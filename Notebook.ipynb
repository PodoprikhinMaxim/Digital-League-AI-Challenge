{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QMIKTlv2rdbZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import gc\n",
    "import  matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "soYhQnADsW-S"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, test=False, folder='dataset/train/'):\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.dataset = dataset\n",
    "        self.folder = folder\n",
    "        if test:\n",
    "            self.y_data = torch.zeros(len(dataset))\n",
    "        else:\n",
    "            self.y_data = torch.tensor(dataset.sign.values,dtype=torch.long)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.dataset.iloc[index].filename, self.y_data[index]\n",
    "        image = np.array(Image.open(self.folder+image).convert('RGB'))\n",
    "        if self.transform != None:\n",
    "            image = self.transform(image)\n",
    "        y = label\n",
    "        return image, y, self.dataset.iloc[index].filename\n",
    "\n",
    "class img_CNN(nn.Module):\n",
    "    def __init__(self, model_type, num_classes):\n",
    "        super(img_CNN, self).__init__()\n",
    "        self.model_type = model_type\n",
    "        num_features = 2000 * (model_type == 'Mixed') + 1000 * (model_type != 'Mixed')\n",
    "        if model_type == 'VGG':\n",
    "            self.model = models.vgg11(pretrained=True)\n",
    "        elif model_type == 'ResNext':\n",
    "            #self.model = models.resnext101_32x8d(pretrained=True)\n",
    "            self.model = models.resnext50_32x4d(pretrained=True)\n",
    "        elif model_type == 'ResNet':\n",
    "            self.model = models.resnet18(pretrained=True)\n",
    "        elif model_type == 'DenseNet':\n",
    "            self.model = models.densenet161(pretrained=True)\n",
    "        elif model_type == 'GoogleNet':\n",
    "            self.model = models.googlenet(pretrained=True)\n",
    "        elif model_type == 'Inception':\n",
    "            self.model = models.inception_v3(pretrained=True)\n",
    "        elif model_type == 'Wide ResNet':\n",
    "            self.model = models.wide_resnet50_2(pretrained=True)\n",
    "        elif model_type == 'Mixed':\n",
    "            self.model1 = models.densenet161(pretrained=True)\n",
    "            self.model2 = models.resnext101_32x8d(pretrained=True)\n",
    "            self.model1.classifier = nn.Sequential(self.model1.classifier, nn.ReLU(), nn.Dropout(0.5), nn.Linear(1000, 64))\n",
    "            self.model2.fc = nn.Sequential(self.model2.fc, nn.ReLU(), nn.Dropout(0.5), nn.Linear(1000, 64))\n",
    "        else:\n",
    "            raise ValueError('Wrong model type!')\n",
    "        if model_type == 'Mixed':\n",
    "            self.conc_models = nn.Linear(128, num_classes)\n",
    "        else:\n",
    "            self.conc_models = nn.Sequential(nn.ReLU(), nn.Dropout(0.5), nn.Linear(num_features, 512), \n",
    "                                             nn.ReLU(), nn.Dropout(0.5), nn.Linear(512, num_classes))\n",
    "            \n",
    "    def forward(self, image):\n",
    "        if self.model_type == 'Mixed':\n",
    "            img_feature1 = self.model1(image)\n",
    "            img_feature2 = self.model2(image)\n",
    "            img_feature = torch.cat((img_feature1, img_feature2), 1)\n",
    "        else:\n",
    "            img_feature = self.model(image)\n",
    "        img_feature = self.conc_models(img_feature)\n",
    "        return img_feature\n",
    "\n",
    "def get_weightedAccuracyM(y_true, y_pred, num_classes, weights):\n",
    "    y_NtrueByClass = np.array([np.sum(y_true == i) for i in range(num_classes)])\n",
    "    y_NtruepositiveByClass = np.array([np.sum((y_true == i) & (y_true == y_pred)) for i in range(num_classes)])\n",
    "    acc = (y_NtruepositiveByClass / y_NtrueByClass) * weights\n",
    "    return np.sum(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JJ29IFibvRfl"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "     transforms.ToPILImage(),\n",
    "     transforms.Resize((128//2, 198//2)),\n",
    "     transforms.RandomChoice((transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET), \n",
    "                             transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10), \n",
    "                             transforms.AutoAugment(transforms.AutoAugmentPolicy.SVHN),\n",
    "                             #transforms.RandomAffine(degrees=(0, 0), translate=(0.0, 0.0), scale=(1, 1)),\n",
    "                             #transforms.RandomAffine(degrees=(0, 0), translate=(0.0, 0.3), scale=(1, 1)),\n",
    "                             #transforms.RandomAffine(degrees=(0, 30), translate=(0.0, 0.0), scale=(1, 1)),\n",
    "                             #transforms.RandomHorizontalFlip(p=0.9),\n",
    "                             #transforms.RandomVerticalFlip(p=0.9)\n",
    "                        )),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "     ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((128//2, 198//2)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "my-x0i_-vUXy"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_targets_noV.csv')\n",
    "valid = pd.read_csv('valid_targets.csv')\n",
    "train_dataset = CustomDataset(train, data_transforms['train'], folder='dataset/train/')\n",
    "valid_dataset =  CustomDataset(valid, data_transforms['val'], folder='dataset/train/')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = 1, shuffle=False)\n",
    "\n",
    "dataloaders={}\n",
    "dataloaders['train'] = train_loader\n",
    "dataloaders['val'] = valid_loader\n",
    "dataset_sizes = {'train': len(train_dataset), 'val':len(valid_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WlnEjY0svdTm"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MKniw_lvn0M"
   },
   "outputs": [],
   "source": [
    "model_type = 'ResNext'\n",
    "num_classes = 5\n",
    "weights = 1 / np.array([0.4, 0.3, 0.09, 0.12, 0.06])\n",
    "model = img_CNN(model_type, num_classes).cuda()\n",
    "\n",
    "best_model_wts_single = copy.deepcopy(model.state_dict())\n",
    "best_res_single = 0\n",
    "best_epoch_single = -1\n",
    "\n",
    "class_weights=compute_class_weight('balanced', np.unique(train.sign), train.sign.to_numpy())\n",
    "class_weights=torch.tensor(class_weights, dtype=torch.float).cuda()\n",
    "criterion = nn.CrossEntropyLoss(class_weights)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "num_epochs = 40\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    print('-' * 10)\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  \n",
    "        else:\n",
    "            model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for inputs, labels, _ in tqdm(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                preds = torch.argmax(outputs, dim=1).detach().cpu().tolist()\n",
    "                trues = labels.cpu().tolist()\n",
    "                for j in range(len(preds)):\n",
    "                    y_true.append(trues[j])\n",
    "                    y_pred.append(preds[j])\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()                      \n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "        tmp_wAcc_score = get_weightedAccuracyM(np.array(y_true), np.array(y_pred), num_classes=5, weights=weights)\n",
    "        tmp_f1_score = f1_score(y_true, y_pred, average='macro')\n",
    "        print('{} results for model {} - f1: {:.8f}, weghted accuracy: {:.8f}'.format(\n",
    "            phase, model_type, \n",
    "            tmp_f1_score, tmp_wAcc_score / get_weightedAccuracyM(np.array(y_true), np.array(y_true), num_classes=5, weights=weights)))\n",
    "        if phase == 'val' and tmp_wAcc_score >= best_res_single:\n",
    "            best_res_single = tmp_wAcc_score\n",
    "            best_epoch_single = epoch\n",
    "            best_model_wts_single = copy.deepcopy(model.state_dict())\n",
    "    time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3QE34oh2YTv"
   },
   "outputs": [],
   "source": [
    "best_model = img_CNN(model_type, num_classes)\n",
    "best_model.load_state_dict(best_model_wts_single)\n",
    "input_shape = train_dataset.__getitem__(0)[0].shape\n",
    "sample_input = torch.randn(1, input_shape[0], input_shape[1], input_shape[2], requires_grad=True)\n",
    "torch.onnx.export(best_model, sample_input, \"best_model.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw2A18nDRT89"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "Untitled8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
